## ✅ 혼동 행렬 (Confusion Matrix)

| 실제 / 예측 | 예측: 음성(Negative) | 예측: 양성(Positive) |
| --- | --- | --- |
| **실제: 음성** | ✅ **TN** (True Negative)정답 | ❌ **FP** (False Positive)오답 |
| **실제: 양성** | ❌ **FN** (False Negative)오답 | ✅ **TP** (True Positive)정답 |
- **양성(Positive)**: 예측하고자 하는 '관심 대상' (예: 암 환자, 스팸메일 등)
- **음성(Negative)**: 양성이 아닌 나머지 (예: 건강한 사람, 정상 메일 등)

---

## ✅ 주요 분류 성능 지표

### 📌 1. **정확도 (Accuracy)**

- **정의**: 전체 데이터 중 맞춘 비율
- **공식**: (TP + TN) / (TP + TN + FP + FN)
- **주의**: 데이터가 **불균형**할 때는 믿을 수 없음 (예: 전체 95%가 음성일 때, 무조건 음성이라고 예측해도 95% 정확도)
- ✅ 적절한 사용 상황: **클래스 분포가 비교적 균형잡힌 경우**

---

### 📌 2. **재현율 (Recall, 민감도, Sensitivity)**

- **정의**: 실제 양성 중, 모델이 맞춘 비율
- **공식**: TP / (TP + FN)
- **의미**: 놓치지 않고 잘 잡아내는지
- ✅ 적절한 사용 상황: **암 진단, 사기 탐지 등 ‘양성을 놓치면 위험한’ 문제에서 중요**

---

### 📌 3. **정밀도 (Precision)**

- **정의**: 모델이 양성이라고 예측한 것 중 실제로 맞춘 비율
- **공식**: TP / (TP + FP)
- **의미**: 틀리게 ‘양성’이라고 한 비율이 얼마나 적은지
- ✅ 적절한 사용 상황: **스팸 필터링, 광고 클릭 예측 등 ‘양성 예측의 신뢰도’가 중요한 문제**

---

### 📌 4. **F1 점수 (F1 Score)**

- **정의**: 정밀도와 재현율의 조화 평균
- **공식**: 2 × (Precision × Recall) / (Precision + Recall)
- **의미**: 정밀도와 재현율 사이의 **균형을 평가**
- ✅ 적절한 사용 상황: **불균형한 데이터셋에서, 정밀도와 재현율을 모두 고려해야 하는 경우**

---

### 📌 + α. 기타 유용한 지표들 (선택적으로 학습)

| 지표 | 설명 |
| --- | --- |
| **Specificity (특이도)** | 실제 음성 중에서 음성을 맞춘 비율 → TN / (TN + FP) |
| **ROC-AUC (곡선 아래 면적)** | 분류 모델의 **종합적 성능**을 나타내는 지표 (0.5~1.0) |
| **PR AUC** | Precision-Recall 곡선 면적. 불균형 데이터에서 ROC보다 더 유용함 |

---

## ✅ 요약 정리표

| 지표 | 초점 | 공식 | 사용 예시 |
| --- | --- | --- | --- |
| 정확도 | 전체 예측 정확 | (TP+TN)/(TP+TN+FP+FN) | 데이터 균형 잡혔을 때 |
| 정밀도 | 예측 신뢰도 | TP / (TP + FP) | 스팸 필터, 광고 타겟 |
| 재현율 | 놓치지 않기 | TP / (TP + FN) | 암 진단, 응급 대응 |
| F1 점수 | 정밀도+재현율 균형 | 2PR / (P + R) | 불균형 데이터 |